draft_model:
  model_name_or_path: meta-llama/Llama-3.2-1B-Instruct
  dtype: bfloat16
  attn_implementation: flash_attention_2
target_model:
  model_name_or_path: meta-llama/Llama-3.1-8B-Instruct
  dtype: bfloat16
  attn_implementation: flash_attention_2
dataset:
  dataset_name: ruler
  seq_len: 16384
  task: cwe
sparse_config:
  sparse_type: specpc
  max_capacity_prompt: 1024
  window_size: 64
  pool_type: max
  kernel_size: 32
  neighbor_tokens: 32
  reduction_type: max
  lookahead_tokens: 1
  starting_layer_index: 8
  weighted_query: true
