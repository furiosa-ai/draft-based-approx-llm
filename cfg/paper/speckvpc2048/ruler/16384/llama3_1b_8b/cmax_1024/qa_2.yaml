draft_model:
  model_name_or_path: meta-llama/Llama-3.2-1B-Instruct
  dtype: bfloat16
  attn_implementation: flash_attention_2
target_model:
  model_name_or_path: meta-llama/Llama-3.1-8B-Instruct
  dtype: bfloat16
  attn_implementation: flash_attention_2
dataset:
  dataset_name: ruler
  seq_len: 16384
  task: qa_2
sparse_config:
  sparse_type: speckvpc
  specpc_config:
    max_capacity_prompt: 2048
    window_size: 64
    pool_type: max
    kernel_size: 32
    neighbor_tokens: 32
    reduction_type: max
    lookahead_tokens: null
    starting_layer_index: 8
    weighted_query: true
  speckv_config:
    max_capacity_prompt: 1024
    window_size: 32
    pool_type: max
    kernel_size: 7
    reduction_type: max
    prefill_window_size: 2048
    prefill_vertical_size: 2048
